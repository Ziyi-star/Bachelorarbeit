{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f163eb8",
   "metadata": {},
   "source": [
    "## Combine all datasets and Train Test Spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c29d18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a0e0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('../../')   # Add parent directory to Python path\n",
    "from utils.preprocessing import *\n",
    "from utils.segmentation import *\n",
    "from utils.visualization import *\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "np.random.seed(42)  # For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfe69668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_samples(data, n=190):\n",
    "    indices = np.random.choice(data.shape[0], n, replace=False)\n",
    "    return data[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71deede5",
   "metadata": {},
   "source": [
    "## 1. Combine all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8bbb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../../data/Curb/P3/handlebar/Accelerometer/segments_100hz_0.5s_50overlap.npz')\n",
    "data_curb_0 = data['segments_0']\n",
    "data_curb_1 = data['segments_1']\n",
    "data= np.load('../../data/RoadRoughness/Raw/Asphalt/P1/segments_100hz_0.5s_50overlap.npz')\n",
    "data_asphalt= data['segments']\n",
    "data_asphalt = select_random_samples(data_asphalt, 190)\n",
    "data= np.load('../../data/RoadRoughness/Raw/Cobblestone/P1/segments_100hz_0.5s_50overlap.npz')\n",
    "data_cobblestone= data['segments']\n",
    "data_cobblestone = select_random_samples(data_cobblestone, 190)\n",
    "data= np.load('../../data/RoadRoughness/Raw/CompactGravel/P1/segments_100hz_0.5s_50overlap.npz')\n",
    "data_compact_gravel= data['segments']\n",
    "data_compact_gravel = select_random_samples(data_compact_gravel, 190)\n",
    "data= np.load('../../data/RoadRoughness/Raw/Dirt/P1/segments_100hz_0.5s_50overlap.npz')\n",
    "data_Dirt= data['segments']\n",
    "data_Dirt = select_random_samples(data_Dirt, 190)\n",
    "data= np.load('../../data/RoadRoughness/Raw/PavingStone/P1/segments_100hz_0.5s_50overlap.npz')\n",
    "data_PavingStone= data['segments']\n",
    "data_PavingStone = select_random_samples(data_PavingStone, 190)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e91720d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels\n",
    "# Assign labels for each surface type\n",
    "datasets = [\n",
    "    (data_curb_0, \"curb_0\"),\n",
    "    (data_curb_1, \"curb_1\"),\n",
    "    (data_asphalt, \"asphalt\"),\n",
    "    (data_cobblestone, \"cobblestone\"),\n",
    "    (data_compact_gravel, \"compact_gravel\"),\n",
    "    (data_Dirt, \"dirt\"),\n",
    "    (data_PavingStone, \"paving_stone\")\n",
    "]\n",
    "\n",
    "# Combine all into a single list of (sensor_values, label)\n",
    "combined_dataset = []\n",
    "for data, label in datasets:\n",
    "    for segment in data:\n",
    "        combined_dataset.append((segment, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa1f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the combined dataset\n",
    "with open('../../data/TrainTest/combined_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(combined_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a903e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1326\n",
      "Shape of first sample's sensor values: (50, 3)\n",
      "Number of samples per label:\n",
      "curb_0: 188\n",
      "curb_1: 188\n",
      "asphalt: 190\n",
      "cobblestone: 190\n",
      "compact_gravel: 190\n",
      "dirt: 190\n",
      "paving_stone: 190\n"
     ]
    }
   ],
   "source": [
    "# Show number of samples\n",
    "print(\"Number of samples:\", len(combined_dataset))\n",
    "# Show shape of sensor values for the first sample\n",
    "print(\"Shape of first sample's sensor values:\", combined_dataset[0][0].shape)\n",
    "# # Show first 3 samples (sensor values and labels)\n",
    "# for i in range(3):\n",
    "#     print(combined_dataset[i][0], combined_dataset[i][1])\n",
    "\n",
    "# Count samples for each label\n",
    "from collections import Counter\n",
    "label_counts = Counter(label for _, label in combined_dataset)\n",
    "print(\"Number of samples per label:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4d92a",
   "metadata": {},
   "source": [
    "## 2. Train Test Spilt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4d9ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060 266\n",
      "Label train: 1060, Label test: 266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 80% train, 20% test\n",
    "train_set, test_set = train_test_split(combined_dataset, test_size=0.2, random_state=42, shuffle=True, stratify=[label for data, label in combined_dataset])\n",
    "print(len(train_set), len(test_set))\n",
    "# Separate sensor values and labels\n",
    "X_train = [x for x, _ in train_set]\n",
    "y_train = [label for _, label in train_set]\n",
    "X_test = [x for x, _ in test_set]\n",
    "y_test = [label for _, label in test_set]\n",
    "print(f\"Label train: {len(y_train)}, Label test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a93ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train and test sets\n",
    "with open('../../data/TrainTest/train_set.pkl', 'wb') as f:\n",
    "    pickle.dump(train_set, f)\n",
    "with open('../../data/TrainTest/test_set.pkl', 'wb') as f:\n",
    "    pickle.dump(test_set, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db636c",
   "metadata": {},
   "source": [
    "## 3. Normalise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09be39a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.94318687,  4.45824211,  5.85580769],\n",
       "       [-2.94290638,  4.458214  ,  5.85604172],\n",
       "       [-2.94262588,  4.45818589,  5.85627574],\n",
       "       [-2.94234539,  4.45815778,  5.85650977],\n",
       "       [-2.9420649 ,  4.45812967,  5.85674379],\n",
       "       [-2.94178441,  4.45810157,  5.85697782],\n",
       "       [-2.94150391,  4.45807346,  5.85721184],\n",
       "       [-2.94122342,  4.45804535,  5.85744586],\n",
       "       [-2.94094293,  4.45801724,  5.85767989],\n",
       "       [-2.94066243,  4.45798913,  5.85791391],\n",
       "       [-2.94038194,  4.45796102,  5.85814794],\n",
       "       [-2.94010145,  4.45793292,  5.85838196],\n",
       "       [-2.93982095,  4.45790481,  5.85861599],\n",
       "       [-2.93954046,  4.4578767 ,  5.85885001],\n",
       "       [-2.93925997,  4.45784859,  5.85908403],\n",
       "       [-2.93897947,  4.45782048,  5.85931806],\n",
       "       [-2.93869898,  4.45779237,  5.85955208],\n",
       "       [-2.93841849,  4.45776426,  5.85978611],\n",
       "       [-2.93813799,  4.45773616,  5.86002013],\n",
       "       [-2.9378575 ,  4.45770805,  5.86025416],\n",
       "       [-2.93757701,  4.45767994,  5.86048818],\n",
       "       [-2.93729652,  4.45765183,  5.8607222 ],\n",
       "       [-2.93701602,  4.45762372,  5.86095623],\n",
       "       [-2.93673553,  4.45759561,  5.86119025],\n",
       "       [-2.93645504,  4.45756751,  5.86142428],\n",
       "       [-2.93617454,  4.4575394 ,  5.8616583 ],\n",
       "       [-2.93589405,  4.45751129,  5.86189233],\n",
       "       [-2.93561356,  4.45748318,  5.86212635],\n",
       "       [-2.93533306,  4.45745507,  5.86236037],\n",
       "       [-2.93505257,  4.45742696,  5.8625944 ],\n",
       "       [-2.93477208,  4.45739886,  5.86282842],\n",
       "       [-2.93449158,  4.45737075,  5.86306245],\n",
       "       [-2.93421109,  4.45734264,  5.86329647],\n",
       "       [-2.9339306 ,  4.45731453,  5.8635305 ],\n",
       "       [-2.9336501 ,  4.45728642,  5.86376452],\n",
       "       [-2.93336961,  4.45725831,  5.86399854],\n",
       "       [-2.93308912,  4.45723021,  5.86423257],\n",
       "       [-2.93280862,  4.4572021 ,  5.86446659],\n",
       "       [-2.93252813,  4.45717399,  5.86470062],\n",
       "       [-2.93224764,  4.45714588,  5.86493464],\n",
       "       [-2.93196715,  4.45711777,  5.86516867],\n",
       "       [-2.93168665,  4.45708966,  5.86540269],\n",
       "       [-2.93140616,  4.45706156,  5.86563671],\n",
       "       [-2.93112567,  4.45703345,  5.86587074],\n",
       "       [-2.93084517,  4.45700534,  5.86610476],\n",
       "       [-2.93056468,  4.45697723,  5.86633879],\n",
       "       [-2.93028419,  4.45694912,  5.86657281],\n",
       "       [-2.93000369,  4.45692101,  5.86680684],\n",
       "       [-2.9297232 ,  4.45689291,  5.86704086],\n",
       "       [-2.92944271,  4.4568648 ,  5.86727488]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dbc1cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1060, 50, 3)\n",
      "[[-2.94318687  4.45824211  5.85580769]\n",
      " [-2.94290638  4.458214    5.85604172]\n",
      " [-2.94262588  4.45818589  5.85627574]\n",
      " [-2.94234539  4.45815778  5.85650977]\n",
      " [-2.9420649   4.45812967  5.85674379]\n",
      " [-2.94178441  4.45810157  5.85697782]\n",
      " [-2.94150391  4.45807346  5.85721184]\n",
      " [-2.94122342  4.45804535  5.85744586]\n",
      " [-2.94094293  4.45801724  5.85767989]\n",
      " [-2.94066243  4.45798913  5.85791391]\n",
      " [-2.94038194  4.45796102  5.85814794]\n",
      " [-2.94010145  4.45793292  5.85838196]\n",
      " [-2.93982095  4.45790481  5.85861599]\n",
      " [-2.93954046  4.4578767   5.85885001]\n",
      " [-2.93925997  4.45784859  5.85908403]\n",
      " [-2.93897947  4.45782048  5.85931806]\n",
      " [-2.93869898  4.45779237  5.85955208]\n",
      " [-2.93841849  4.45776426  5.85978611]\n",
      " [-2.93813799  4.45773616  5.86002013]\n",
      " [-2.9378575   4.45770805  5.86025416]\n",
      " [-2.93757701  4.45767994  5.86048818]\n",
      " [-2.93729652  4.45765183  5.8607222 ]\n",
      " [-2.93701602  4.45762372  5.86095623]\n",
      " [-2.93673553  4.45759561  5.86119025]\n",
      " [-2.93645504  4.45756751  5.86142428]\n",
      " [-2.93617454  4.4575394   5.8616583 ]\n",
      " [-2.93589405  4.45751129  5.86189233]\n",
      " [-2.93561356  4.45748318  5.86212635]\n",
      " [-2.93533306  4.45745507  5.86236037]\n",
      " [-2.93505257  4.45742696  5.8625944 ]\n",
      " [-2.93477208  4.45739886  5.86282842]\n",
      " [-2.93449158  4.45737075  5.86306245]\n",
      " [-2.93421109  4.45734264  5.86329647]\n",
      " [-2.9339306   4.45731453  5.8635305 ]\n",
      " [-2.9336501   4.45728642  5.86376452]\n",
      " [-2.93336961  4.45725831  5.86399854]\n",
      " [-2.93308912  4.45723021  5.86423257]\n",
      " [-2.93280862  4.4572021   5.86446659]\n",
      " [-2.93252813  4.45717399  5.86470062]\n",
      " [-2.93224764  4.45714588  5.86493464]\n",
      " [-2.93196715  4.45711777  5.86516867]\n",
      " [-2.93168665  4.45708966  5.86540269]\n",
      " [-2.93140616  4.45706156  5.86563671]\n",
      " [-2.93112567  4.45703345  5.86587074]\n",
      " [-2.93084517  4.45700534  5.86610476]\n",
      " [-2.93056468  4.45697723  5.86633879]\n",
      " [-2.93028419  4.45694912  5.86657281]\n",
      " [-2.93000369  4.45692101  5.86680684]\n",
      " [-2.9297232   4.45689291  5.86704086]\n",
      " [-2.92944271  4.4568648   5.86727488]]\n"
     ]
    }
   ],
   "source": [
    "X_train_array = np.stack(X_train)\n",
    "print(X_train_array.shape)\n",
    "print(X_train_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f4c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack X_train to shape (num_samples, segment_length, num_channels)\n",
    "X_train_array = np.stack(X_train)  # shape: (N, L, C)\n",
    "\n",
    "# Reshape to 2D for scaler: (N*L, C)\n",
    "# Your sensor data is 3D: (N, L, C) where, N = number of samples, L = segment length (timesteps), C = number of channels (features per timestep)\n",
    "N, L, C = X_train_array.shape\n",
    "X_train_reshaped = X_train_array.reshape(-1, C)\n",
    "# you are converting your 3D array (N, L, C) into a 2D array with shape (N*L, C).\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
    "\n",
    "# Reshape back to original shape\n",
    "X_train_normalized = X_train_scaled.reshape(N, L, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab7d2e",
   "metadata": {},
   "source": [
    "# 4. Labels from string to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37ce17a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['asphalt' 'cobblestone' 'compact_gravel' 'curb_0' 'curb_1' 'dirt'\n",
      " 'paving_stone']\n",
      "First 10 y_train_int: [6 5 5 5 1 1 4 4 2 6]\n",
      "First 10 y_test_int: [0 3 4 2 6 5 4 2 5 6]\n",
      "0: asphalt\n",
      "1: cobblestone\n",
      "2: compact_gravel\n",
      "3: curb_0\n",
      "4: curb_1\n",
      "5: dirt\n",
      "6: paving_stone\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_int = label_encoder.fit_transform(y_train)\n",
    "y_test_int = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"Classes:\", label_encoder.classes_)\n",
    "print(\"First 10 y_train_int:\", y_train_int[:10])\n",
    "print(\"First 10 y_test_int:\", y_test_int[:10])\n",
    "for idx, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"{idx}: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb795435",
   "metadata": {},
   "source": [
    "## 5: One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8368df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1060, 7)\n",
      "(266, 7)\n"
     ]
    }
   ],
   "source": [
    "y_train_onehot = to_categorical(y_train_int)\n",
    "y_test_onehot = to_categorical(y_test_int)\n",
    "\n",
    "print(y_train_onehot.shape)\n",
    "print(y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "771ce62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select an index and check that the one-hot encoding matches the original label\n",
    "r = np.random.randint(len(y_train_int))\n",
    "assert y_train_onehot[r].argmax() == y_train_int[r]\n",
    "r = np.random.randint(len(y_test_int))\n",
    "assert y_test_onehot[r].argmax() == y_test_int[r]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c20030",
   "metadata": {},
   "source": [
    "## 6. Save train, test data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b376d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98049343",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
