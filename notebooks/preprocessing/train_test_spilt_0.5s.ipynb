{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f163eb8",
   "metadata": {},
   "source": [
    "## Combine all datasets and Train Test Spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c29d18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a0e0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('../../')   # Add parent directory to Python path\n",
    "import pickle\n",
    "from utils.preprocessing import *\n",
    "from utils.segmentation import *\n",
    "from utils.visualization import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfe69668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_samples(data, n=190):\n",
    "    indices = np.random.choice(data.shape[0], n, replace=False)\n",
    "    return data[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71deede5",
   "metadata": {},
   "source": [
    "## 1. Combine all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8bbb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curb (scene 0): (1189, 50, 3)\n",
      "Curb (scene 1): (1189, 50, 3)\n",
      "Asphalt: (1413, 50, 3)\n",
      "Cobblestone: (985, 50, 3)\n",
      "Compact Gravel: (970, 50, 3)\n",
      "Dirt: (1166, 50, 3)\n",
      "Paving Stone: (1299, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load the curb data (which appears to be stored as a dictionary with scene_0 and scene_1)\n",
    "with open('../data_all/curb_0.5s_combined_all.pkl', 'rb') as f:\n",
    "    curb_data = pickle.load(f)\n",
    "    data_curb_0 = curb_data['scene_0']\n",
    "    data_curb_1 = curb_data['scene_1']\n",
    "    \n",
    "# Load the other surface types (these appear to be stored as arrays)\n",
    "with open('../data_all/asphalt_0.5s_combined_all.pkl', 'rb') as f:\n",
    "    data_asphalt = pickle.load(f)\n",
    "        \n",
    "with open('../data_all/cobblestone_0.5s_combined_all.pkl', 'rb') as f:\n",
    "    data_cobblestone = pickle.load(f)\n",
    "    \n",
    "with open('../data_all/compactgravel_0.5s_combined_all.pkl', 'rb') as f:\n",
    "    data_compact_gravel = pickle.load(f)\n",
    "    \n",
    "with open('../data_all/dirt_0.5s_combined_all.pkl', 'rb') as f:\n",
    "    data_Dirt = pickle.load(f)\n",
    "    \n",
    "with open('../data_all/pavingstone_0.5s_combined_all.pkl', 'rb') as f:\n",
    "    data_PavingStone = pickle.load(f)\n",
    "\n",
    "# Print shapes to verify the data was loaded correctly\n",
    "print(\"Curb (scene 0):\", data_curb_0.shape)\n",
    "print(\"Curb (scene 1):\", data_curb_1.shape)\n",
    "print(\"Asphalt:\", data_asphalt.shape)\n",
    "print(\"Cobblestone:\", data_cobblestone.shape)\n",
    "print(\"Compact Gravel:\", data_compact_gravel.shape)\n",
    "print(\"Dirt:\", data_Dirt.shape)\n",
    "print(\"Paving Stone:\", data_PavingStone.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91720d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels\n",
    "# Assign labels for each surface type\n",
    "datasets = [\n",
    "    (data_curb_0, \"curb_0\"),\n",
    "    (data_curb_1, \"curb_1\"),\n",
    "    (data_asphalt, \"asphalt\"),\n",
    "    (data_cobblestone, \"cobblestone\"),\n",
    "    (data_compact_gravel, \"compact_gravel\"),\n",
    "    (data_Dirt, \"dirt\"),\n",
    "    (data_PavingStone, \"paving_stone\")\n",
    "]\n",
    "\n",
    "# Combine all into a single list of (sensor_values, label)\n",
    "combined_dataset = []\n",
    "for data, label in datasets:\n",
    "    for segment in data:\n",
    "        combined_dataset.append((segment, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efa1f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the combined dataset\n",
    "with open('../data_all/TrainTest/combined_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(combined_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a903e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 8211\n",
      "Shape of first sample's sensor values: (50, 3)\n",
      "Number of samples per label:\n",
      "curb_0: 1189\n",
      "curb_1: 1189\n",
      "asphalt: 1413\n",
      "cobblestone: 985\n",
      "compact_gravel: 970\n",
      "dirt: 1166\n",
      "paving_stone: 1299\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(combined_dataset))\n",
    "print(\"Shape of first sample's sensor values:\", combined_dataset[0][0].shape)\n",
    "# # Show first 3 samples (sensor values and labels)\n",
    "# for i in range(3):\n",
    "#     print(combined_dataset[i][0], combined_dataset[i][1])\n",
    "\n",
    "from collections import Counter\n",
    "label_counts = Counter(label for _, label in combined_dataset)\n",
    "print(\"Number of samples per label:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4d92a",
   "metadata": {},
   "source": [
    "## 2. Train Test Spilt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d9ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6568 1643\n",
      "Label train: 6568, Label test: 1643\n"
     ]
    }
   ],
   "source": [
    "# 80% train, 20% test\n",
    "train_set, test_set = train_test_split(combined_dataset, test_size=0.2, random_state=42, shuffle=True, stratify=[label for data, label in combined_dataset])\n",
    "print(len(train_set), len(test_set))\n",
    "# Separate sensor values and labels\n",
    "X_train = [x for x, _ in train_set]\n",
    "y_train = [label for _, label in train_set]\n",
    "X_test = [x for x, _ in test_set]\n",
    "y_test = [label for _, label in test_set]\n",
    "print(f\"Label train: {len(y_train)}, Label test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db636c",
   "metadata": {},
   "source": [
    "## 3. Normalise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09be39a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.67996092e+00,  3.95304273e+00,  1.03451697e+01],\n",
       "       [-1.06012012e+00,  5.73828797e+00,  6.95753070e+00],\n",
       "       [-1.46754798e+00,  7.08828850e+00,  7.79297480e+00],\n",
       "       [ 1.82811650e+00,  6.70812865e+00,  5.70718100e+00],\n",
       "       [ 9.21934633e-01,  6.30229603e+00,  8.07477933e+00],\n",
       "       [ 9.38285550e-01,  7.18983400e+00,  5.40643325e+00],\n",
       "       [ 1.23449707e+00,  6.59761007e+00,  5.02213583e+00],\n",
       "       [-2.51645187e-01,  4.56759937e+00,  1.03034940e+01],\n",
       "       [-1.58973160e+00,  2.58305220e+00,  1.35897370e+01],\n",
       "       [ 3.53041048e-01,  4.43180657e+00,  8.56301517e+00],\n",
       "       [ 3.55732961e-01,  3.44476737e+00,  9.74447133e+00],\n",
       "       [ 8.84746215e-01,  2.73365035e+00,  1.47447225e+01],\n",
       "       [-1.41844533e+00,  4.95892560e+00,  7.00179770e+00],\n",
       "       [ 2.07397903e+00,  4.39611357e+00,  8.68465000e+00],\n",
       "       [-9.72383289e-01,  3.75224520e+00,  1.14302148e+01],\n",
       "       [-2.06036985e+00,  5.83968400e+00,  7.98260550e+00],\n",
       "       [-1.45952217e+00,  5.07567547e+00,  6.01097000e+00],\n",
       "       [-2.33419855e+00,  3.15912425e+00,  1.02815100e+01],\n",
       "       [-9.64108007e-02,  4.87996230e+00,  9.30927667e+00],\n",
       "       [-2.48300220e+00,  5.95274450e+00,  4.78998230e+00],\n",
       "       [-7.84048223e-01,  5.26032127e+00,  7.72881720e+00],\n",
       "       [-7.46261580e-01,  4.03235490e+00,  9.52358400e+00],\n",
       "       [-3.56032067e-01,  4.69950357e+00,  7.92642447e+00],\n",
       "       [ 2.74277315e-01,  6.46600510e+00,  6.82821840e+00],\n",
       "       [ 8.84546777e-01,  5.95354220e+00,  6.94805910e+00],\n",
       "       [ 6.93320360e-01,  4.35299300e+00,  8.33420100e+00],\n",
       "       [-9.98554800e-01,  4.77068995e+00,  8.84342375e+00],\n",
       "       [ 7.04686267e-01,  5.42811820e+00,  8.02004333e+00],\n",
       "       [ 9.04187870e-01,  5.46480813e+00,  9.78694390e+00],\n",
       "       [ 8.65902700e-02,  4.35747980e+00,  9.04591675e+00],\n",
       "       [-6.30508753e-01,  5.08125870e+00,  7.83430067e+00],\n",
       "       [ 2.44815665e-01,  5.37727070e+00,  8.67577650e+00],\n",
       "       [-2.50249360e-01,  5.12452887e+00,  7.98255633e+00],\n",
       "       [ 1.97692020e+00,  4.86460850e+00,  8.27393220e+00],\n",
       "       [-6.22433033e-01,  4.64865627e+00,  8.47657457e+00],\n",
       "       [ 5.39880000e-02,  4.89362150e+00,  9.35384250e+00],\n",
       "       [ 2.75074893e-01,  5.10698140e+00,  8.70130000e+00],\n",
       "       [-3.24925357e-01,  5.23898560e+00,  8.34457033e+00],\n",
       "       [ 6.83599529e-01,  5.14860650e+00,  8.50872800e+00],\n",
       "       [-2.47073900e+00,  5.28694200e+00,  7.69157875e+00],\n",
       "       [-5.11366134e-01,  5.96530670e+00,  7.09252583e+00],\n",
       "       [-1.32547420e+00,  5.49152815e+00,  1.06866450e+01],\n",
       "       [ 9.21236767e-02,  4.67318260e+00,  1.17249303e+01],\n",
       "       [-1.60378935e+00,  5.50917505e+00,  7.43838810e+00],\n",
       "       [-3.33649204e-01,  6.18365190e+00,  5.46715100e+00],\n",
       "       [-6.44367173e-01,  5.83270457e+00,  7.73519800e+00],\n",
       "       [ 1.44566667e-02,  4.57876577e+00,  7.73469953e+00],\n",
       "       [ 5.17447906e-01,  3.82313230e+00,  8.43230750e+00],\n",
       "       [-1.67746837e+00,  4.74357140e+00,  8.48764120e+00],\n",
       "       [-6.24925533e-01,  5.46959387e+00,  8.25773083e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8dbc1cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1060, 50, 3)\n",
      "[[-2.94318687  4.45824211  5.85580769]\n",
      " [-2.94290638  4.458214    5.85604172]\n",
      " [-2.94262588  4.45818589  5.85627574]\n",
      " [-2.94234539  4.45815778  5.85650977]\n",
      " [-2.9420649   4.45812967  5.85674379]\n",
      " [-2.94178441  4.45810157  5.85697782]\n",
      " [-2.94150391  4.45807346  5.85721184]\n",
      " [-2.94122342  4.45804535  5.85744586]\n",
      " [-2.94094293  4.45801724  5.85767989]\n",
      " [-2.94066243  4.45798913  5.85791391]\n",
      " [-2.94038194  4.45796102  5.85814794]\n",
      " [-2.94010145  4.45793292  5.85838196]\n",
      " [-2.93982095  4.45790481  5.85861599]\n",
      " [-2.93954046  4.4578767   5.85885001]\n",
      " [-2.93925997  4.45784859  5.85908403]\n",
      " [-2.93897947  4.45782048  5.85931806]\n",
      " [-2.93869898  4.45779237  5.85955208]\n",
      " [-2.93841849  4.45776426  5.85978611]\n",
      " [-2.93813799  4.45773616  5.86002013]\n",
      " [-2.9378575   4.45770805  5.86025416]\n",
      " [-2.93757701  4.45767994  5.86048818]\n",
      " [-2.93729652  4.45765183  5.8607222 ]\n",
      " [-2.93701602  4.45762372  5.86095623]\n",
      " [-2.93673553  4.45759561  5.86119025]\n",
      " [-2.93645504  4.45756751  5.86142428]\n",
      " [-2.93617454  4.4575394   5.8616583 ]\n",
      " [-2.93589405  4.45751129  5.86189233]\n",
      " [-2.93561356  4.45748318  5.86212635]\n",
      " [-2.93533306  4.45745507  5.86236037]\n",
      " [-2.93505257  4.45742696  5.8625944 ]\n",
      " [-2.93477208  4.45739886  5.86282842]\n",
      " [-2.93449158  4.45737075  5.86306245]\n",
      " [-2.93421109  4.45734264  5.86329647]\n",
      " [-2.9339306   4.45731453  5.8635305 ]\n",
      " [-2.9336501   4.45728642  5.86376452]\n",
      " [-2.93336961  4.45725831  5.86399854]\n",
      " [-2.93308912  4.45723021  5.86423257]\n",
      " [-2.93280862  4.4572021   5.86446659]\n",
      " [-2.93252813  4.45717399  5.86470062]\n",
      " [-2.93224764  4.45714588  5.86493464]\n",
      " [-2.93196715  4.45711777  5.86516867]\n",
      " [-2.93168665  4.45708966  5.86540269]\n",
      " [-2.93140616  4.45706156  5.86563671]\n",
      " [-2.93112567  4.45703345  5.86587074]\n",
      " [-2.93084517  4.45700534  5.86610476]\n",
      " [-2.93056468  4.45697723  5.86633879]\n",
      " [-2.93028419  4.45694912  5.86657281]\n",
      " [-2.93000369  4.45692101  5.86680684]\n",
      " [-2.9297232   4.45689291  5.86704086]\n",
      " [-2.92944271  4.4568648   5.86727488]]\n"
     ]
    }
   ],
   "source": [
    "X_train_array = np.stack(X_train)\n",
    "print(X_train_array.shape)\n",
    "print(X_train_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "448f4c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack X_train to shape (num_samples, segment_length, num_channels)\n",
    "X_train_array = np.stack(X_train)  # shape: (N, L, C)\n",
    "\n",
    "# Reshape to 2D for scaler: (N*L, C)\n",
    "# Your sensor data is 3D: (N, L, C) where, N = number of samples, L = segment length (timesteps), C = number of channels (features per timestep)\n",
    "N, L, C = X_train_array.shape\n",
    "X_train_reshaped = X_train_array.reshape(-1, C)\n",
    "# you are converting your 3D array (N, L, C) into a 2D array with shape (N*L, C).\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
    "\n",
    "# Reshape back to original shape\n",
    "X_train_normalized = X_train_scaled.reshape(N, L, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab7d2e",
   "metadata": {},
   "source": [
    "# 4. Labels from string to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37ce17a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['asphalt' 'cobblestone' 'compact_gravel' 'curb_0' 'curb_1' 'dirt'\n",
      " 'paving_stone']\n",
      "First 10 y_train_int: [0 3 0 4 0 0 6 4 6 5]\n",
      "First 10 y_test_int: [5 4 1 5 4 4 5 1 0 5]\n",
      "0: asphalt\n",
      "1: cobblestone\n",
      "2: compact_gravel\n",
      "3: curb_0\n",
      "4: curb_1\n",
      "5: dirt\n",
      "6: paving_stone\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_int = label_encoder.fit_transform(y_train)\n",
    "y_test_int = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"Classes:\", label_encoder.classes_)\n",
    "print(\"First 10 y_train_int:\", y_train_int[:10])\n",
    "print(\"First 10 y_test_int:\", y_test_int[:10])\n",
    "for idx, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"{idx}: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb795435",
   "metadata": {},
   "source": [
    "## 5: One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8368df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6568, 7)\n",
      "(1643, 7)\n"
     ]
    }
   ],
   "source": [
    "y_train_onehot = to_categorical(y_train_int)\n",
    "y_test_onehot = to_categorical(y_test_int)\n",
    "\n",
    "print(y_train_onehot.shape)\n",
    "print(y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "771ce62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select an index and check that the one-hot encoding matches the original label\n",
    "r = np.random.randint(len(y_train_int))\n",
    "assert y_train_onehot[r].argmax() == y_train_int[r]\n",
    "r = np.random.randint(len(y_test_int))\n",
    "assert y_test_onehot[r].argmax() == y_test_int[r]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c20030",
   "metadata": {},
   "source": [
    "## 6. Save train, test data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b376d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data\n",
    "with open('../data_all/TrainTest/X_test_data.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open('../data_all/TrainTest/y_test_onehot.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test_onehot, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24da61",
   "metadata": {},
   "source": [
    "## 6. Train, validation Spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfba3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5254, 50, 3) (5254, 7)\n",
      "Validation shape: (1314, 50, 3) (1314, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_normalized,\n",
    "    y_train_onehot,\n",
    "    test_size=0.2,           # 20% for validation\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data_all/TrainTest/X_train_data_normalized.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_normalized, f)\n",
    "with open('../data_all/TrainTest/X_val_data_normalized.pkl', 'wb') as f:\n",
    "    pickle.dump(X_val, f)\n",
    "with open('../data_all/TrainTest/y_train_onehot.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train_onehot, f)\n",
    "with open('../data_all/TrainTest/y_val_onehot.pkl', 'wb') as f:\n",
    "    pickle.dump(y_val_onehot, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6b38a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
